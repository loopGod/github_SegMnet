{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['“', '人们', '常', '说', '生活', '是', '一', '部', '教科书', '，', '而', '血', '与', '火', '的', '战争', '更', '是', '不可多得', '的', '教科书', '，', '她', '确实', '是', '名副其实', '的', '‘', '我', '的', '大学', '’', '。'], ['“', '心', '静', '渐', '知', '春', '似', '海', '，', '花', '深', '每', '觉', '影', '生', '香', '。'], ['“', '吃', '屎', '的', '东西', '，', '连', '一', '捆', '麦', '也', '铡', '不', '动', '呀', '？'], ['他', '“', '严格要求', '自己', '，', '从', '一个', '科举', '出身', '的', '进士', '成为', '一个', '伟大', '的', '民主主义', '者', '，', '进而', '成为', '一', '位', '杰出', '的', '党外', '共产主义', '战士', '，', '献身', '于', '崇高', '的', '共产主义', '事业', '。'], ['“', '征', '而', '未', '用', '的', '耕地', '和', '有', '收益', '的', '土地', '，', '不准', '荒芜', '。']]\n",
      "86924\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "train_data_txt = \"../training/msr_training.txt\"\n",
    "init_train_data = []\n",
    "with open(train_data_txt,encoding='gbk') as trt:\n",
    "    init_train_data = trt.readlines()\n",
    "all_data = \"\".join(init_train_data)\n",
    "train_data_split = [line.strip().split() for line in init_train_data]\n",
    "\n",
    "print(train_data_split[0:5])\n",
    "print(len(train_data_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<UNK>', '!', '#', '%', '&', \"'\", '(', ')', '*']\n"
     ]
    }
   ],
   "source": [
    "# 读取字符词典文件\n",
    "char_vocab_path = \"../training/char_vocabs.txt\"\n",
    "special_words = ['<PAD>', '<UNK>'] # 特殊词表示\n",
    "with open(char_vocab_path, \"r\", encoding=\"utf8\") as fo:\n",
    "    char_vocabs = [line.strip() for line in fo]\n",
    "char_vocabs = special_words + char_vocabs\n",
    "print(char_vocabs[0:10])\n",
    "\n",
    "# 字符和索引编号对应\n",
    "idx2vocab = {idx: char for idx, char in enumerate(char_vocabs)}\n",
    "vocab2idx = {char: idx for idx, char in idx2vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"BMES\"标记的标签\n",
    "label2idx = {\"S\": 0,\n",
    "             \"B\": 1, \n",
    "             \"M\": 2,\n",
    "             \"E\": 3\n",
    "             }\n",
    "# 索引和BMES标签对应\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取data\n",
    "def data_list(path, vocab2idx, label2idx):\n",
    "    with open(train_data_txt,encoding='gbk') as trt:\n",
    "        lines = trt.readlines()\n",
    "    datas, labels= [], []\n",
    "    for line in lines: # line是一个字符串\n",
    "        mline = line.strip().split() #mline是个词列表\n",
    "        sent, tag = [],[]\n",
    "        for i,word in enumerate(mline):\n",
    "            if len(word)==1:\n",
    "                sent.append(word)\n",
    "                tag.append(\"S\")\n",
    "            else:\n",
    "                s_word = [\"M\" for i in word]\n",
    "                s_word[0] = \"B\"\n",
    "                s_word[-1] = \"E\"\n",
    "                sent+=list(word)\n",
    "                tag+=s_word\n",
    "\n",
    "        sent_ids = [vocab2idx[char] if char in vocab2idx else vocab2idx['<UNK>'] for char in sent]\n",
    "        tag_ids = [label2idx[label] if label in label2idx else 0 for label in tag]\n",
    "        datas.append(sent_ids)\n",
    "        labels.append(tag_ids)\n",
    "\n",
    "    return datas, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86924 86924\n",
      "[122, 5800, 6506, 563, 2572, 240, 3007, 2530, 6209, 6440, 6802, 3007, 2530, 3903, 2102, 2065, 6209, 6440, 182]\n",
      "['“', '这', '首', '先', '是', '个', '民', '族', '问', '题', '，', '民', '族', '的', '感', '情', '问', '题', '。']\n",
      "[0, 0, 1, 3, 0, 0, 1, 3, 1, 3, 0, 1, 3, 0, 1, 3, 1, 3, 0]\n",
      "['S', 'S', 'B', 'E', 'S', 'S', 'B', 'E', 'B', 'E', 'S', 'B', 'E', 'S', 'B', 'E', 'B', 'E', 'S']\n"
     ]
    }
   ],
   "source": [
    "datas, labels = data_list(train_data_txt, vocab2idx, label2idx)\n",
    "print(len(datas),len(labels))\n",
    "print(datas[5])\n",
    "print([idx2vocab[idx] for idx in datas[5]])\n",
    "print(labels[5])\n",
    "print([idx2label[idx] for idx in labels[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 3, 0, 0, 1, 3, 0, 0, 0, 1, 2, 3, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 1, 2, 2, 3, 0, 1, 2, 3, 0, 0, 1, 3, 0, 1, 2, 2, 3, 0, 0, 0, 0, 1, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 2, 2, 3, 1, 3, 0, 0, 1, 3, 1, 3, 1, 3, 0, 1, 3, 1, 3, 1, 3, 1, 3, 0, 1, 2, 2, 3, 0, 0, 1, 3, 1, 3, 0, 0, 1, 3, 0, 1, 3, 1, 2, 2, 3, 1, 3, 0, 1, 3, 0, 1, 3, 0, 1, 2, 2, 3, 1, 3, 0], [0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 1, 3, 0, 1, 3, 0, 1, 3, 1, 3, 0], [0, 0, 1, 3, 0, 0, 1, 3, 1, 3, 0, 1, 3, 0, 1, 3, 1, 3, 0], [0, 0, 0, 0, 1, 3, 1, 2, 3, 0, 0, 1, 2, 3, 0, 0, 1, 3, 0], [0, 1, 3, 1, 3, 1, 3, 0, 1, 2, 3, 1, 3, 0, 1, 2, 3, 1, 2, 2, 3, 0, 1, 3, 0, 1, 3, 0], [0, 1, 3, 1, 3, 0, 0, 1, 3, 1, 3, 0, 1, 3, 0, 1, 3, 1, 3, 0, 0, 0, 1, 3, 0, 1, 3, 0, 1, 3, 1, 3, 0, 0], [0, 0, 1, 3, 0, 1, 3, 1, 3, 0, 1, 3, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "snum = 70000\n",
    "train_datas = datas[0:snum]\n",
    "train_labels = labels[0:snum]\n",
    "test_datas = datas[snum:]\n",
    "test_labels = labels[snum:]\n",
    "print(train_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 19:31:38.402781 139756498421568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0825 19:31:38.425765 139756498421568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0825 19:31:38.430186 139756498421568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding sequences\n",
      "x_train shape: (70000, 100)\n",
      "x_test shape: (16924, 100)\n",
      "trainlabels shape: (70000, 100)\n",
      "testlabels shape: (16924, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 19:31:41.651870 139756498421568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0825 19:31:41.658265 139756498421568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0825 19:31:41.797614 139756498421568 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainlabels shape: (70000, 100, 4)\n",
      "testlabels shape: (16924, 100, 4)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 128)         880000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         49280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 4)           516       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 4)           0         \n",
      "=================================================================\n",
      "Total params: 1,028,356\n",
      "Trainable params: 1,028,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0825 19:31:41.972900 139756498421568 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63000 samples, validate on 7000 samples\n",
      "Epoch 1/2\n",
      "63000/63000 [==============================] - 62s 992us/step - loss: 0.1337 - acc: 0.9520 - val_loss: 0.0817 - val_acc: 0.9715\n",
      "Epoch 2/2\n",
      "63000/63000 [==============================] - 62s 978us/step - loss: 0.0643 - acc: 0.9776 - val_loss: 0.0664 - val_acc: 0.9769\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Masking, Embedding, Bidirectional, LSTM, Dense, Input, TimeDistributed, Activation\n",
    "from keras.preprocessing import sequence\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_viterbi_accuracy\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "from crf_keras import CRF\n",
    "from keras.layers import Dense, Embedding, Conv1D, Input\n",
    "from keras.models import Model # 这里我们学习使用Model型的模型\n",
    "import keras.backend as K # 引入Keras后端来自定义loss，注意Keras模型内的一切运算\n",
    "                          # 必须要通过Keras后端完成，比如取对数要用K.log不能用np.log\n",
    "\n",
    "embedding_size = 128\n",
    "EPOCHS = 2\n",
    "MAX_LEN=100\n",
    "CLASS_NUMS=4\n",
    "\n",
    "train_crf = False  # true train CRF-transaction Matrix\n",
    "\n",
    "print('padding sequences')\n",
    "train_datas = sequence.pad_sequences(train_datas, maxlen=MAX_LEN)\n",
    "train_labels = sequence.pad_sequences(train_labels, maxlen=MAX_LEN)\n",
    "test_datas = sequence.pad_sequences(test_datas, maxlen=MAX_LEN)\n",
    "test_labels = sequence.pad_sequences(test_labels, maxlen=MAX_LEN)\n",
    "print('x_train shape:', train_datas.shape)\n",
    "print('x_test shape:', test_datas.shape)\n",
    "print('trainlabels shape:', train_labels.shape)\n",
    "print('testlabels shape:', test_labels.shape)\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, CLASS_NUMS)#.reshape((70000,100, 5))\n",
    "test_labels = keras.utils.to_categorical(test_labels, CLASS_NUMS)#.reshape((16924,100, 5))\n",
    "print('trainlabels shape:', train_labels.shape)\n",
    "print('testlabels shape:', test_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "sequence = Input(shape=(None,), dtype='int32') # 建立输入层，输入长度设为None\n",
    "embedding = Embedding(len(char_vocabs)+1,\n",
    "                      embedding_size,\n",
    "                     )(sequence) # 去掉了mask_zero=True\n",
    "cnn = Conv1D(128, 3, activation='relu', padding='same')(embedding)\n",
    "cnn = Conv1D(128, 3, activation='relu', padding='same')(cnn)\n",
    "cnn = Conv1D(128, 3, activation='relu', padding='same')(cnn) # 层叠了3层CNN\n",
    "\n",
    "if train_crf:\n",
    "    crf = CRF(True) # 定义crf层，参数为True，自动mask掉最后一个标签\n",
    "tag_score = Dense(CLASS_NUMS)(cnn) # 变成了5分类，第五个标签用来mask掉\n",
    "if train_crf:\n",
    "    tag_score = crf(tag_score) # 包装一下原来的tag_score\n",
    "else:\n",
    "    tag_score = Activation('softmax')(tag_score)\n",
    "\n",
    "model = Model(inputs=sequence, outputs=tag_score)\n",
    "model.summary()\n",
    "\n",
    "if train_crf == False:\n",
    "    model.compile(loss=\"categorical_crossentropy\", # 用crf自带的loss\n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"] # 用crf自带的accuracy\n",
    "             )\n",
    "else:\n",
    "    model.compile(loss=crf.loss, # 用crf自带的loss\n",
    "                  optimizer='adam',\n",
    "                  metrics=[crf.accuracy] # 用crf自带的accuracy\n",
    "                 )\n",
    "model.fit(train_datas, train_labels, epochs=EPOCHS, verbose=1, validation_split=0.1)\n",
    "\n",
    "\n",
    "model.save_weights(\"../model/CNN_seg_weight.h5\")\n",
    "model.save(\"../model/CNN_seg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16924/16924 [==============================] - 3s 190us/step\n",
      "['loss', 'acc']\n",
      "[0.07004244630322956, 0.97601512709117]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "score = model.evaluate(test_datas, test_labels, batch_size=BATCH_SIZE)\n",
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_in_dict(d): # 定义一个求字典中最大值的函数\n",
    "    key,value = list(d.items())[0]\n",
    "    for i,j in list(d.items())[1:]:\n",
    "        if j > value:\n",
    "            key,value = i,j\n",
    "    return key,value\n",
    "\n",
    "def viterbi(nodes, trans): # viterbi算法，跟前面的HMM一致\n",
    "    paths = nodes[0] # 初始化起始路径\n",
    "    for l in range(1, len(nodes)): # 遍历后面的节点\n",
    "        paths_old,paths = paths,{}\n",
    "        for n,ns in nodes[l].items(): # 当前时刻的所有节点\n",
    "            max_path,max_score = '',-1e10\n",
    "            for p,ps in paths_old.items(): # 截止至前一时刻的最优路径集合\n",
    "                score = ns + ps + trans[p[-1]+n] # 计算新分数\n",
    "                if score > max_score: # 如果新分数大于已有的最大分\n",
    "                    max_path,max_score = p+n, score # 更新路径\n",
    "            paths[max_path] = max_score # 储存到当前时刻所有节点的最优路径\n",
    "#     print(paths)\n",
    "    return max_in_dict(paths)\n",
    "\n",
    "\n",
    "def cut(s, trans): # 分词函数，也跟前面的HMM基本一致\n",
    "    if not s: # 空字符直接返回\n",
    "        return []\n",
    "    # 字序列转化为id序列。注意，经过我们前面对语料的预处理，字符集是没有空格的，\n",
    "    # 所以这里简单将空格的id跟句号的id等同起来\n",
    "    sent_ids = np.array([[vocab2idx.get(c, 0) if c != ' ' else vocab2idx[u'。']\n",
    "                          for c in s]])\n",
    "    probas = model.predict(sent_ids)[0] # 模型预测\n",
    "    nodes = [dict(zip('SBME', i)) for i in probas[:, :4]] # 只取前4个\n",
    "    nodes[0] = {i:j for i,j in nodes[0].items() if i in 'BS'} # 首字标签只能是b或s\n",
    "    nodes[-1] = {i:j for i,j in nodes[-1].items() if i in 'ES'} # 末字标签只能是e或s\n",
    "    tags = viterbi(nodes, trans)[0]\n",
    "    result = [s[0]]\n",
    "    for i,j in zip(s[1:], tags[1:]):\n",
    "        if j in 'BS': # 词的开始\n",
    "            result.append(i)\n",
    "        else: # 接着原来的词\n",
    "            result[-1] += i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['储', '存到', '当前', '时刻', '所有', '节点', '的最', '优路', '径.']\n"
     ]
    }
   ],
   "source": [
    "t_ = model.get_weights()[-1][:4,:4] # 从训练模型中取出最新得到的转移矩阵\n",
    "\n",
    "trans = {}\n",
    "for i in 'SBME':\n",
    "    for j in 'SBME':\n",
    "        trans[i+j] = t_[label2idx[i], label2idx[j]]\n",
    "result = cut(\"储存到当前时刻所有节点的最优路径.\", trans)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2551752   1.3712068  -1.969512   -0.94762987]\n",
      " [-1.3502188  -0.11775374  0.6775522   2.1938992 ]\n",
      " [-2.6458318  -0.72990716  1.816428    0.97933584]\n",
      " [ 0.73843807  1.0811784  -1.9546679  -0.7160042 ]]\n"
     ]
    }
   ],
   "source": [
    "t_ = model.get_weights()[-1][:4,:4] \n",
    "print(t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "class mCRF(object):\n",
    "    '''实现条件随机场预测问题的维特比算法\n",
    "    '''\n",
    "    def __init__(self, V, VW, E, EW):\n",
    "        '''\n",
    "        :param V:是定义在节点上的特征函数，称为状态特征\n",
    "        :param VW:是V对应的权值\n",
    "        :param E:是定义在边上的特征函数，称为转移特征\n",
    "        :param EW:是E对应的权值\n",
    "        '''\n",
    "        self.V  = V  #点分布表\n",
    "        self.VW = VW #点权值表\n",
    "        self.E  = E  #边分布表\n",
    "        self.EW = EW #边权值表\n",
    "        self.D  = [] #Delta表，最大非规范化概率的局部状态路径概率\n",
    "        self.P  = [] #Psi表，当前状态和最优前导状态的索引表s\n",
    "        self.BP = [] #BestPath，最优路径\n",
    "        return \n",
    "        \n",
    "    def Viterbi(self):\n",
    "        '''\n",
    "        条件随机场预测问题的维特比算法，此算法一定要结合CRF参数化形式对应的状态路径图来理解，更容易理解.\n",
    "        '''\n",
    "        self.D = np.full(shape=(np.shape(self.V)), fill_value=.0)\n",
    "        self.P = np.full(shape=(np.shape(self.V)), fill_value=.0)\n",
    "        for i in range(np.shape(self.V)[0]):\n",
    "            #初始化\n",
    "            if 0 == i:\n",
    "                self.D[i] = np.multiply(self.V[i], self.VW[i])\n",
    "                self.P[i] = np.array([0,0,0,0])\n",
    "            #递推求解布局最优状态路径\n",
    "            else:\n",
    "                for y in range(np.shape(self.V)[1]): #delta[i][y=1,2...]\n",
    "                    for l in range(np.shape(self.V)[1]): #V[i-1][l=1,2...]\n",
    "                        #前导状态的最优状态路径的概率 + 前导状态到当前状体的转移概率 + 当前状态的概率\n",
    "                        delta = self.D[i-1, l] + self.E[i-1][l,y]*self.EW[i-1][l,y]  + self.V[i,y]*self.VW[i,y]            #\n",
    "                        if 0 == l or delta > self.D[i, y]:\n",
    "                            self.D[i, y], self.P[i, y] = delta, l        \n",
    "        #返回，得到所有的最优前导状态\n",
    "        N = np.shape(self.V)[0]\n",
    "        self.BP = np.full(shape=(N,), fill_value=0.0)\n",
    "        t_range = -1 * np.array(sorted(-1*np.arange(N)))\n",
    "        for t in t_range:\n",
    "            if N-1 == t:#得到最优状态\n",
    "                self.BP[t] = np.argmax(self.D[-1])\n",
    "            else: #得到最优前导状态\n",
    "                self.BP[t] = self.P[t+1, int(self.BP[t+1])]\n",
    "        \n",
    "        #最优状态路径表现在存储的是状态的下标，我们执行存储值+1转换成示例中的状态值\n",
    "        #也可以不用转换，只要你能理解，self.BP中存储的0是状态1就可以~~~~\n",
    "        self.BP += 1\n",
    "        return self.BP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.57617512e-02 6.47181571e-01 2.05800310e-01 1.11256406e-01]\n",
      " [7.41250589e-02 6.17801137e-02 2.44409423e-02 8.39653850e-01]\n",
      " [5.69670379e-01 2.93144047e-01 1.94347799e-02 1.17750809e-01]\n",
      " [7.00858891e-01 4.45698248e-03 7.29888529e-02 2.21695349e-01]\n",
      " [1.34184060e-03 9.75391865e-01 2.26224195e-02 6.43991865e-04]\n",
      " [1.60890061e-03 5.06933839e-06 7.33532652e-04 9.97652471e-01]\n",
      " [9.99859810e-01 9.06646983e-06 3.14862373e-05 9.96470844e-05]\n",
      " [2.27284720e-04 9.99171615e-01 5.99993044e-04 1.17581817e-06]\n",
      " [8.48629934e-05 4.42486780e-05 9.87949371e-01 1.19215017e-02]\n",
      " [1.17292600e-02 1.00604609e-06 8.22218935e-05 9.88187492e-01]\n",
      " [9.99966979e-01 4.50291992e-07 2.75359344e-05 5.00498663e-06]\n",
      " [3.64758773e-04 9.99609888e-01 2.54160732e-05 5.73575782e-08]\n",
      " [4.16930357e-04 3.73509858e-04 7.40593791e-01 2.58615851e-01]\n",
      " [3.01884532e-01 1.38192344e-02 1.30059076e-02 6.71290338e-01]\n",
      " [8.67853779e-03 9.72069263e-01 1.86600089e-02 5.92120632e-04]\n",
      " [6.15844547e-05 1.10575780e-02 9.79111493e-01 9.76943318e-03]\n",
      " [2.08678422e-03 3.43221905e-06 2.25096868e-04 9.97684717e-01]\n",
      " [1.36582553e-03 9.98466492e-01 1.67352351e-04 3.09813800e-07]\n",
      " [3.27417918e-04 6.17151323e-04 9.98595059e-01 4.60338197e-04]\n",
      " [3.05230817e-04 2.09197708e-04 9.83966172e-01 1.55193089e-02]\n",
      " [3.53356302e-02 8.50117474e-04 1.43690035e-02 9.49445248e-01]\n",
      " [8.69790733e-01 9.65683139e-04 1.25746131e-01 3.49750114e-03]\n",
      " [2.30118856e-01 7.05080271e-01 6.47133142e-02 8.74760954e-05]\n",
      " [1.09370433e-01 5.98384668e-06 2.23733776e-04 8.90399814e-01]\n",
      " [9.99982476e-01 8.66961443e-07 1.32606137e-05 3.46405773e-06]\n",
      " [3.48206982e-02 9.65149999e-01 2.08794390e-05 8.56186398e-06]\n",
      " [3.91294658e-02 8.57040379e-03 1.93469867e-01 7.58830309e-01]]\n",
      "最优状态路径为: [2. 4. 1. 1. 2. 4. 1. 2. 3. 4. 1. 2. 3. 4. 2. 3. 4. 2. 3. 3. 4. 1. 2. 4.\n",
      " 1. 2. 4.]\n",
      "废除 先 前 存在 的 所有制   关系, 并不是 共产主义 所 独具 的 特征 \n"
     ]
    }
   ],
   "source": [
    "s = \"最优状态路径表现在存储的是状态的下标，我们执行存储值+1转换成示例中的状态值\"\n",
    "sent_ids = np.array([[vocab2idx[c] if c != ' ' else vocab2idx[u'。']\n",
    "                          for c in s]])\n",
    "S = np.array(model.predict(sent_ids)[0][:, :4])  \n",
    "print(S)\n",
    "SW = S\n",
    "crf_tran = [[ 0.2551752,   1.3712068,  -1.969512,   -0.94762987],\n",
    "             [-1.3502188,  -0.11775374,  0.6775522,   2.1938992 ],\n",
    "             [-2.6458318,  -0.72990716,  1.816428,    0.97933584],\n",
    "             [ 0.73843807,  1.0811784,  -1.9546679,  -0.7160042 ]]\n",
    "def_tran = [[0.5,0.5,0,0],[0,0,0.5,0.5],[0,0,0.5,0.5],[0.5,0.5,0,0]]\n",
    "E = np.array([def_tran for i in s])\n",
    "EW = E\n",
    "\n",
    "crf = mCRF(S, SW, E, EW)\n",
    "ret = crf.Viterbi()\n",
    "print('最优状态路径为:', ret)\n",
    "# SBME\n",
    "res_str = ''\n",
    "for i in range(len(s)):\n",
    "    if ret[i] == 1:\n",
    "        res_str+=s[i]+' '\n",
    "    elif ret[i] == 4:\n",
    "        res_str+=s[i]+\" \"\n",
    "    else:\n",
    "        res_str+=s[i]\n",
    "print(res_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.609243   -0.60307544 -0.5321975  -1.350059  ]\n",
      " [ 2.1912084  -0.50220716 -1.9891578  -1.5365913 ]\n",
      " [-1.2706817   0.44745424  0.21643111 -0.7846817 ]\n",
      " [-0.79834855 -2.2858722  -0.7888813   2.3905082 ]\n",
      " [-0.4829742   1.3791542  -0.72924024 -1.4593649 ]\n",
      " [-0.21598284 -4.392511   -1.1265367   3.3144002 ]\n",
      " [-2.0698733   2.1803555  -0.8679491  -0.8824459 ]\n",
      " [-1.6855692  -1.5468001  -1.2390535   2.8636303 ]\n",
      " [ 3.8489604  -4.0107965  -0.8362013  -1.6430526 ]\n",
      " [ 0.26872087  1.424837   -0.645475   -3.6561563 ]\n",
      " [ 0.7524922  -3.4886906  -1.6522187   2.5781956 ]\n",
      " [ 4.5253954  -1.041991    0.11846626 -5.8860846 ]\n",
      " [ 4.114442   -5.469349   -1.738103   -0.07103527]\n",
      " [-1.6244731   2.3750694  -0.2490682  -3.1855345 ]\n",
      " [ 1.146612   -5.647822   -2.6322265   4.5583663 ]\n",
      " [ 5.8469195  -1.4046049   0.5016388  -8.909219  ]\n",
      " [ 2.5169191   1.220266   -2.5986495  -2.5697556 ]\n",
      " [ 0.16200602 -1.077709   -0.27034223  0.06126173]]\n",
      "最优状态路径为: [1. 3. 1. 3. 4. 2. 1. 4. 2. 4. 2. 4. 2. 4. 2. 4. 1. 3.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2551752  -1.3502188  -2.6458318   0.73843807]\n",
      " [ 1.3712068  -0.11775374 -0.72990716  1.0811784 ]\n",
      " [-1.969512    0.6775522   1.816428   -1.9546679 ]\n",
      " [-0.94762987  2.1938992   0.97933584 -0.7160042 ]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
